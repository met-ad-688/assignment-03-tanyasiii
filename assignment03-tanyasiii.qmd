---
title: Assignment 03
author:
  - name: Tracy Anyasi
    affiliations:
      - id: bu id U00345116
        name: Boston University
        city: Boston
        state: MA
number-sections: true
date: '2024-11-21'
format:
  html:
    theme: cerulean
    toc: true
    toc-depth: 2
  docx: default
  pdf: default
date-modified: today
date-format: long
execute: 
  freeze: true
---

# Load the dataset

```{python}
import pandas as pd
import plotly.express as px
import plotly.io as pio
from pyspark.sql import SparkSession
import re
import numpy as np
import plotly.graph_objects as go
from pyspark.sql.functions import col, split, explode, regexp_replace, transform, when
from pyspark.sql import functions as F
from pyspark.sql.functions import col, monotonically_increasing_id

np.random.seed(51)

pio.renderers.default = "notebook"

# Initialize Spark Session
spark = SparkSession.builder.appName("LightcastData").getOrCreate()

# Load Data
df = spark.read.option("header", "true").option("inferSchema", "true").option("multiLine","true").option("escape", "\"").csv("data/lightcast_job_postings.csv")
df.createOrReplaceTempView("job_postings")

# Show Schema and Sample Data
#print("---This is Diagnostic check, No need to print it in the final doc---")

#df.printSchema() # comment this line when rendering the submission
#df.show(5)


```

```{python}
## Casting Salaries
df = df.withColumn("SALARY_FROM", col("SALARY_FROM").cast("float")) \
        .withColumn("SALARY_TO", col("SALARY_TO").cast("float")) \
        .withColumn("SALARY", col("SALARY").cast("float")) \
        .withColumn("MIN_YEARS_EXPERIENCE", col("MIN_YEARS_EXPERIENCE").cast("float")) \
        .withColumn("MAX_YEARS_EXPERIENCE", col("MAX_YEARS_EXPERIENCE").cast("float")) \
        .withColumn("EDUCATION_LEVELS_NAME",regexp_replace(col("EDUCATION_LEVELS_NAME"), r"[\n\r]", "")) \

## Computing Medians
def compute_median(sdf, col_name):
    q = sdf.approxQuantile(col_name, [0.5], 0.01)
    return q[0] if q else None

median_from = compute_median(df, "SALARY_FROM")
median_to = compute_median(df, "SALARY_TO")
median_salary = compute_median(df, "SALARY")

print("Medians:", median_from, median_to, median_salary)

## Imput missing using the medians
df = df.fillna({
    "SALARY_FROM": median_from,
    "SALARY_TO": median_to,
    "SALARY": median_salary
})

## compute average salary
df = df.withColumn("Average_Salary", (col("SALARY_FROM") + col("SALARY_TO"))/2)

## removing null values in Employmet type column
df = df.na.drop(subset=["EMPLOYMENT_TYPE_NAME"])

# df.select("Average_Salary", "SALARY", "EDUCATION_LEVELS_NAME", "REMOTE_TYPE_NAME", "MAX_YEARS_EXPERIENCE", "LOT_V6_SPECIALIZED_OCCUPATION_NAME").show(5, truncate=False)


## selecting required columns & exporting data/ saving to csv
export_cols = [
  "EDUCATION_LEVELS_NAME",
  "REMOTE_TYPE_NAME",
  "MAX_YEARS_EXPERIENCE",
  "Average_Salary",
  "SALARY_TO",
  "SALARY_FROM",
  "SALARY",
  "LOT_V6_SPECIALIZED_OCCUPATION_NAME",
  "LOT_OCCUPATION_NAME",
  "NAICS2_NAME",
  "EMPLOYMENT_TYPE_NAME",
  "MIN_YEARS_EXPERIENCE"

]

df_selected = df.select(*export_cols)

## export
pdf = df_selected.toPandas()
pdf.to_csv("lightcast_cleaned.csv", index=False)

#removing random characters from these columns
pdf["EMPLOYMENT_TYPE_NAME"] = pdf["EMPLOYMENT_TYPE_NAME"].astype(str).apply(
    lambda x: re.sub(r"[^\x00-\x7F]+", "", x)
)
pdf["EDUCATION_LEVELS_NAME"] = pdf["EDUCATION_LEVELS_NAME"].astype(str).str.replace(r"[\n\r\\\"\[\]]", "", regex=True)
print(pdf.columns.tolist())

print("Data cleaning complete. Row retained:", len(pdf))

```

#Question 1a - Salary Distribution by Industry
```{python}
fig = px.box(
  pdf,
  x="NAICS2_NAME",
  y="SALARY",
  title="Salary Distribution by Industry",
  color_discrete_sequence=["purple"],
  points="outliers",
)

fig.update_layout(
  font_family="Times New Roman",
  title_font_size=16,
  xaxis_title="Industry",
  yaxis_title="Salary",
  xaxis_tickangle=45,
)

fig.show()
fig.write_html("Q1a.html")
#fig.write_image("Q1a.png")

```
#Analysis: 

#Question 1b - Salary Distribution by Employment Type
```{python}
fig = px.box(
  pdf,
  x="EMPLOYMENT_TYPE_NAME",
  y="SALARY",
  title="Salary Distribution by Employment Type",
  color_discrete_sequence=["orange"],
  points="outliers",
)

fig.update_layout(
  font_family="Times New Roman",
  title_font_size=16,
  xaxis_title="Employment Type",
  yaxis_title="Salary",
  xaxis_tickangle=45,
)

fig.show()
fig.write_html("Q1b.html")
#fig.write_image("Q1b.png")

```
#Analysis: 

<!-- #Question 2 - Salary Analysis by ONET Occupation Type
```{python}
#aggregate data by median salary for each occupation (saonet)

saonet = pdf.groupby("LOT_OCCUPATION_NAME").agg(
    median_salary=("SALARY", "median"),  # median salary
    job_count=("SALARY", "count")        # number of postings
).reset_index()

fig = px.scatter(
  saonet,
  x="LOT_OCCUPATION_NAME",
  y="median_salary",
  size="job_count",
  size_max=60,
  color_continuous_scale=["plasma"],
  title="Salary Analysis by Occupation"
)

fig.update_layout(
  font_family="Times New Roman",
  title_font_size=16,
  xaxis_title="Occupation",
  yaxis_title="Median Salary",
  xaxis_tickangle=45,
)

fig.show()
fig.write_html("Q2.html")
#fig.write_image("Q2.png")

```
#Analysis:  -->




#Question 2 - Salary Analysis by ONET Occupation Type
```{python}

saonet = spark.sql("""
    SELECT
      LOT_OCCUPATION_NAME AS Occupation_Name,
      PERCENTILE(SALARY, 0.5) AS Median_Salary,
      COUNT(*) AS Job_Postings
    FROM job_postings
    GROUP BY LOT_OCCUPATION_NAME
    ORDER BY Job_Postings DESC
    LIMIT 10
"""
)

saonet_pd = saonet.toPandas()
saonet_pd.head()


fig = px.scatter(
  saonet_pd,
  x="Occupation_Name",
  y="Median_Salary",
  size="Job_Postings",
  title="Salary Analysis by LOT Occupation Type (Bubble Chart)",
  labels={
    "LOT_OCCUPATION_NAME": "LOT Occupation",
    "Median_Salary": "Median Salary",
    "Job_Postings": "Number of Job Postings"
  },
  hover_name="Occupation_Name",
  size_max=60,
  width=1000,
  height=600,
  color="Job_Postings",
  color_continuous_scale="Plasma"
)

fig.update_layout(
  font_family="Times New Roman",
  font_size=16,
  title_font_size=20,
  xaxis_title="LOT Occupation",
  yaxis_title="Median Salary",
  xaxis=dict(
    tickangle=-45,
    showline=True,
    linecolor="black"
  ),
  yaxis=dict(
    showline=True,
    linecolor="black"
  )
)

fig.show()
fig.write_html("Q2a.html")
```






<!-- #Question 3
```{python}
import pandas as pd
import plotly.express as px

# Map education levels into groups
edu_mapping = {
    'GED': 'Associate or Lower',
    'Associate': 'Associate or Lower',
    'No Education Listed': 'Associate or Lower',
    "Bachelor's": 'Bachelor',
    "Master's": 'Master',
    'PhD': 'PhD',
    'Doctorate': 'PhD',
    'Professional Degree': 'PhD'
}

df['EDU_GROUP'] = df['EDU_GROUP'].map(edu_mapping)

# Plot scatter for each education group
for edu in df['EDU_GROUP'].unique():
    subset = df[df['EDU_GROUP'] == edu]
    
    fig = px.scatter(
        subset,
        x='MAX_YEARS_EXPERIENCE',
        y='AVERAGE_SALARY',
        color='LOT_V6_SPECIALIZED_OCCUPATION_NAME',
        hover_data=['LOT_V6_SPECIALIZED_OCCUPATION_NAME', 'MAX_YEARS_EXPERIENCE', 'AVERAGE_SALARY'],
        title=f'Salary vs Experience for {edu} Degrees',
        labels={
            'MAX_YEARS_EXPERIENCE': 'Years of Experience',
            'AVERAGE_SALARY': 'Average Salary'
        }
    )
    
    fig.update_layout(
        font_family="Times New Roman",
        title_font_size=16,
        yaxis=dict(tickprefix="$")
    )
    
    fig.show()
    fig.write_html(f"Salary_vs_Experience_{edu.replace(' ', '_')}.html")
 
``` -->
